{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"becc4537f73348209063fe2b1df598b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61524bbc2acb468087013b08ccde0b6a","IPY_MODEL_d7b6501c6d48459aa2863af75cff87d3","IPY_MODEL_ca7f88428f3c41168ae61da2c5795442"],"layout":"IPY_MODEL_edd93b820b4b4a6ca095309962c0a785"}},"61524bbc2acb468087013b08ccde0b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e69ceb26e144a8089226e14a1c41104","placeholder":"​","style":"IPY_MODEL_a604e3e1a66949338f740fbb54b41737","value":"config.json: 100%"}},"d7b6501c6d48459aa2863af75cff87d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc92fa36e3cf4fa09818aad62b2ad4ef","max":758,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd05448c6a764361b563e16c21ad7a54","value":758}},"ca7f88428f3c41168ae61da2c5795442":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd9a12ee54b843f78a594e7a91118140","placeholder":"​","style":"IPY_MODEL_bbe5986cea7346948841454ba3131a27","value":" 758/758 [00:00&lt;00:00, 41.9kB/s]"}},"edd93b820b4b4a6ca095309962c0a785":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e69ceb26e144a8089226e14a1c41104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a604e3e1a66949338f740fbb54b41737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc92fa36e3cf4fa09818aad62b2ad4ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd05448c6a764361b563e16c21ad7a54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd9a12ee54b843f78a594e7a91118140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe5986cea7346948841454ba3131a27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64654926d29c4a94bf5c4c53d713d227":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8e0d2be3b5745579468a1d19ad066b3","IPY_MODEL_97854ec8707f4100a7be89b5d6e83667","IPY_MODEL_f7e43869170e4409b5603c8d74b195c8"],"layout":"IPY_MODEL_9dc61cff535a42ee982f081acbfdd36b"}},"b8e0d2be3b5745579468a1d19ad066b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc3c3849ec3b41769e8741dcf65a1c0a","placeholder":"​","style":"IPY_MODEL_622baab8572145ff8ee498b4813d03d6","value":"pytorch_model.bin: 100%"}},"97854ec8707f4100a7be89b5d6e83667":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c181af71d85f4f1db0e6ae792d333ead","max":437992753,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6ff29cad73942ceace15846d9923c00","value":437992753}},"f7e43869170e4409b5603c8d74b195c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca386374048c42cbacd15b0f8a40d6d1","placeholder":"​","style":"IPY_MODEL_9a6024847bd34c7faa917a00f14711a1","value":" 438M/438M [00:05&lt;00:00, 77.9MB/s]"}},"9dc61cff535a42ee982f081acbfdd36b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc3c3849ec3b41769e8741dcf65a1c0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"622baab8572145ff8ee498b4813d03d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c181af71d85f4f1db0e6ae792d333ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6ff29cad73942ceace15846d9923c00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca386374048c42cbacd15b0f8a40d6d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a6024847bd34c7faa917a00f14711a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec50e6fdba6640a9b1a698bd26946d6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0613c7ba398447659234348b783445a9","IPY_MODEL_67bf3fa2d00a40059f5ecadb548a2c9a","IPY_MODEL_de57dece0ff94526a5722cbeb50c8af1"],"layout":"IPY_MODEL_7fdfa112ca004b0f955195f4c76f1907"}},"0613c7ba398447659234348b783445a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8179710239894ed4ac0f4ff6cfd00753","placeholder":"​","style":"IPY_MODEL_98bbc134f9f84aeb811f744786a8ada9","value":"model.safetensors: 100%"}},"67bf3fa2d00a40059f5ecadb548a2c9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda58a4be3de4bc680f76fe88f47db15","max":437965908,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7698d5caefc1445f871ebf30a38cf8e4","value":437965908}},"de57dece0ff94526a5722cbeb50c8af1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f2aed6b56264b54bfb8f224e27279d8","placeholder":"​","style":"IPY_MODEL_8f8b37de4ab94d8c818c498ba2b0bf3c","value":" 438M/438M [00:06&lt;00:00, 73.3MB/s]"}},"7fdfa112ca004b0f955195f4c76f1907":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8179710239894ed4ac0f4ff6cfd00753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98bbc134f9f84aeb811f744786a8ada9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eda58a4be3de4bc680f76fe88f47db15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7698d5caefc1445f871ebf30a38cf8e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f2aed6b56264b54bfb8f224e27279d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f8b37de4ab94d8c818c498ba2b0bf3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["\n","\n"],"metadata":{"id":"intro_markdown"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"imports_logging_code","executionInfo":{"status":"ok","timestamp":1752095366233,"user_tz":-360,"elapsed":12,"user":{"displayName":"hulu world","userId":"05131870956520847838"}}},"outputs":[],"source":["import torch\n","from transformers import AutoModelForSequenceClassification, get_scheduler\n","from torch.optim import AdamW\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from sklearn.metrics import accuracy_score, f1_score\n","from tqdm import tqdm\n","import os\n","import logging\n","\n","# --- Configure Logging ---\n","# Create a logger object.\n","logger = logging.getLogger(__name__)\n","logger.setLevel(logging.INFO) # Set the logging level (e.g., INFO, DEBUG, WARNING, ERROR, CRITICAL)\n","\n","# Create a console handler and set its level to INFO\n","ch = logging.StreamHandler()\n","ch.setLevel(logging.INFO)\n","\n","# Create a file handler, set its level, and specify the log file name\n","# You can change 'finetuning.log' to any desired log file name.\n","fh = logging.FileHandler('finetuning.log')\n","fh.setLevel(logging.INFO)\n","\n","# Create a formatter and add it to the handlers\n","formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","ch.setFormatter(formatter)\n","fh.setFormatter(formatter)\n","\n","# Add the handlers to the logger\n","logger.addHandler(ch)\n","logger.addHandler(fh)\n"]},{"cell_type":"markdown","source":["## 2. Global Configuration Constants\n","\n","This cell defines all the global constants used throughout the script, such as model name, number of labels, batch size, epochs, and learning rate. **Remember to adjust `DATA_DIR` to your data's location.**"],"metadata":{"id":"config_constants_markdown"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"config_constants_code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752095366386,"user_tz":-360,"elapsed":156,"user":{"displayName":"hulu world","userId":"05131870956520847838"}},"outputId":"e0154314-0ba8-4569-9906-b62f9eb04dd3"},"outputs":[{"output_type":"stream","name":"stderr","text":["2025-07-09 21:09:25,484 - __main__ - INFO - Using device: cuda\n","2025-07-09 21:09:25,484 - __main__ - INFO - Using device: cuda\n","2025-07-09 21:09:25,484 - __main__ - INFO - Using device: cuda\n","INFO:__main__:Using device: cuda\n","2025-07-09 21:09:25,489 - __main__ - INFO - Looking for data files in: /content\n","2025-07-09 21:09:25,489 - __main__ - INFO - Looking for data files in: /content\n","2025-07-09 21:09:25,489 - __main__ - INFO - Looking for data files in: /content\n","INFO:__main__:Looking for data files in: /content\n"]}],"source":["DATA_DIR = \"./\"\n","MODEL_NAME = \"ProsusAI/finbert\"\n","NUM_LABELS = 3  # Number of output classes for classification (e.g., positive, negative, neutral)\n","BATCH_SIZE = 16  # Number of samples per batch in DataLoader\n","EPOCHS = 3  # Number of full passes through the training dataset\n","LEARNING_RATE = 2e-5  # Learning rate for the AdamW optimizer\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Automatically use GPU if available, else CPU\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"  # Ensures CUDA errors are reported on the exact line for easier debugging\n","\n","logger.info(f\"Using device: {DEVICE}\")\n","logger.info(f\"Looking for data files in: {os.path.abspath(DATA_DIR)}\")"]},{"cell_type":"markdown","source":["## 3. Data Loading Function\n","\n","This function handles loading the preprocessed `input_ids`, `attention_mask`, and `labels` tensors. It includes robust error handling for missing files and an assertion to ensure labels are within the expected range, which helps prevent common CUDA errors during training."],"metadata":{"id":"data_loading_markdown"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"data_loading_code","executionInfo":{"status":"ok","timestamp":1752095366387,"user_tz":-360,"elapsed":3,"user":{"displayName":"hulu world","userId":"05131870956520847838"}}},"outputs":[],"source":["# --- Data Loading Function ---\n","def load_preprocessed_tensors(data_directory, num_labels):\n","    \"\"\"\n","    Loads preprocessed input IDs, attention masks, and labels from specified files.\n","\n","    Args:\n","        data_directory (str): The directory path where the tensor files are stored.\n","        num_labels (int): The expected number of unique labels for validation.\n","\n","    Returns:\n","        tuple: A tuple containing (input_ids, attention_mask, labels) tensors.\n","\n","    Raises:\n","        FileNotFoundError: If any of the required tensor files are not found.\n","        AssertionError: If loaded labels are outside the expected range [0, num_labels-1].\n","    \"\"\"\n","    logger.info(f\"Loading preprocessed tensors from: {os.path.abspath(data_directory)}...\")\n","    try:\n","        input_ids = torch.load(os.path.join(data_directory, \"tokenized_input_ids.pt\"))\n","        attention_mask = torch.load(os.path.join(data_directory, \"tokenized_attention_mask.pt\"))\n","        labels = torch.load(os.path.join(data_directory, \"labels.pt\"))\n","    except FileNotFoundError as e:\n","        logger.error(\n","            f\"Error loading tensor file: {e}. \"\n","            f\"Please ensure 'tokenized_input_ids.pt', 'tokenized_attention_mask.pt', \"\n","            f\"and 'labels.pt' are located in the specified DATA_DIR: '{os.path.abspath(data_directory)}'.\"\n","        )\n","        raise # Re-raise the exception after logging\n","\n","    # Validate label range to prevent CUDA device-side assert errors during training.\n","    logger.info(f\"Unique labels loaded: {torch.unique(labels)}\")\n","    if not (labels.min() >= 0 and labels.max() < num_labels):\n","        logger.error(\n","            f\"Labels loaded for DataLoader are out of range: {torch.unique(labels)}. \"\n","            f\"Expected range [0, {num_labels-1}].\"\n","        )\n","        raise AssertionError(\"Labels are out of the expected range.\")\n","    logger.info(\"Preprocessed tensors loaded and labels validated successfully.\")\n","    return input_ids, attention_mask, labels\n"]},{"cell_type":"markdown","source":["## 4. DataLoader Creation Function\n","\n","This function takes the loaded tensors and creates `DataLoader` objects for both the training and validation datasets, handling the data splitting and batching."],"metadata":{"id":"dataloader_creation_markdown"}},{"cell_type":"code","execution_count":21,"metadata":{"id":"dataloader_creation_code","executionInfo":{"status":"ok","timestamp":1752095366395,"user_tz":-360,"elapsed":7,"user":{"displayName":"hulu world","userId":"05131870956520847838"}}},"outputs":[],"source":["# --- DataLoader Creation Function ---\n","def create_dataloaders(input_ids, attention_mask, labels, batch_size, train_ratio=0.8):\n","    \"\"\"\n","    Creates PyTorch DataLoaders for training and validation datasets.\n","\n","    Args:\n","        input_ids (torch.Tensor): Tensor containing input token IDs.\n","        attention_mask (torch.Tensor): Tensor containing attention masks.\n","        labels (torch.Tensor): Tensor containing corresponding labels.\n","        batch_size (int): The batch size for the DataLoaders.\n","        train_ratio (float): The proportion of data to be used for training.\n","\n","    Returns:\n","        tuple: A tuple containing (train_loader, val_loader).\n","    \"\"\"\n","    logger.info(\"Creating DataLoaders...\")\n","    dataset = TensorDataset(input_ids, attention_mask, labels)\n","\n","    train_size = int(train_ratio * len(dataset))\n","    val_size = len(dataset) - train_size\n","\n","    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","    logger.info(f\"Train dataset size: {len(train_dataset)}, Validation dataset size: {len(val_dataset)}\")\n","    logger.info(\"DataLoaders created successfully.\")\n","    return train_loader, val_loader\n"]},{"cell_type":"markdown","source":["## 5. Model, Optimizer, and Scheduler Setup Function\n","\n","This function initializes the pre-trained Hugging Face model for sequence classification, sets up the `AdamW` optimizer, and configures a linear learning rate scheduler."],"metadata":{"id":"model_setup_markdown"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"model_setup_code","executionInfo":{"status":"ok","timestamp":1752095366396,"user_tz":-360,"elapsed":6,"user":{"displayName":"hulu world","userId":"05131870956520847838"}}},"outputs":[],"source":["# --- Model, Optimizer, Scheduler Initialization Function ---\n","def setup_model_optimizer_scheduler(model_name, num_labels, learning_rate, train_loader, epochs, device):\n","    \"\"\"\n","    Initializes the model, optimizer, and learning rate scheduler.\n","\n","    Args:\n","        model_name (str): The name of the pre-trained model from Hugging Face.\n","        num_labels (int): The number of output classes for the model.\n","        learning_rate (float): The learning rate for the optimizer.\n","        train_loader (DataLoader): The DataLoader for the training set, used to calculate total training steps.\n","        epochs (int): The number of training epochs.\n","        device (torch.device): The device (CPU or GPU) to load the model onto.\n","\n","    Returns:\n","        tuple: A tuple containing (model, optimizer, lr_scheduler).\n","    \"\"\"\n","    logger.info(\"Loading model, optimizer, and scheduler...\")\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","    model.to(device)\n","\n","    optimizer = AdamW(model.parameters(), lr=learning_rate)\n","\n","    num_training_steps = epochs * len(train_loader)\n","    lr_scheduler = get_scheduler(\n","        \"linear\",\n","        optimizer=optimizer,\n","        num_warmup_steps=0,\n","        num_training_steps=num_training_steps\n","    )\n","    logger.info(\"Model, optimizer, and scheduler initialized successfully.\")\n","    return model, optimizer, lr_scheduler\n"]},{"cell_type":"markdown","source":["## 6. Metrics Computation Function\n","\n","This function defines how evaluation metrics (accuracy and F1-score) are calculated from the model's output logits and the true labels."],"metadata":{"id":"metrics_function_markdown"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"metrics_function_code","executionInfo":{"status":"ok","timestamp":1752095366397,"user_tz":-360,"elapsed":5,"user":{"displayName":"hulu world","userId":"05131870956520847838"}}},"outputs":[],"source":["# --- Metrics Function ---\n","def compute_metrics(logits, labels):\n","    \"\"\"\n","    Computes accuracy and weighted F1-score given model logits and true labels.\n","\n","    Args:\n","        logits (torch.Tensor): The raw output logits from the model.\n","        labels (torch.Tensor): The true labels.\n","\n","    Returns:\n","        tuple: A tuple containing (accuracy, f1_score).\n","    \"\"\"\n","    preds = logits.argmax(dim=1)\n","    acc = accuracy_score(labels.cpu(), preds.cpu())\n","    f1 = f1_score(labels.cpu(), preds.cpu(), average='weighted')\n","    return acc, f1\n"]},{"cell_type":"markdown","source":["## 7. Training and Validation Loop Function\n","\n","This is the core training function that iterates through epochs, performs forward and backward passes, updates model weights, and evaluates the model's performance on the validation set after each epoch. Progress bars are included for better visualization."],"metadata":{"id":"training_loop_markdown"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"training_loop_code","executionInfo":{"status":"ok","timestamp":1752095366398,"user_tz":-360,"elapsed":5,"user":{"displayName":"hulu world","userId":"05131870956520847838"}}},"outputs":[],"source":["# --- Training and Validation Loop Function ---\n","def train_and_validate(model, train_loader, val_loader, optimizer, lr_scheduler, epochs, device):\n","    \"\"\"\n","    Executes the training and validation loop for the model.\n","\n","    Args:\n","        model (torch.nn.Module): The PyTorch model to train.\n","        train_loader (DataLoader): DataLoader for the training dataset.\n","        val_loader (DataLoader): DataLoader for the validation dataset.\n","        optimizer (torch.optim.Optimizer): The optimizer for model parameters.\n","        lr_scheduler (torch.optim.lr_scheduler._LRScheduler): The learning rate scheduler.\n","        epochs (int): The number of training epochs.\n","        device (torch.device): The device (CPU or GPU) to perform training on.\n","    \"\"\"\n","    logger.info(\"Starting training and validation loop...\")\n","    for epoch in range(epochs):\n","        # --- Training Phase ---\n","        model.train()  # Set model to training mode\n","        total_loss = 0\n","        for batch_idx, (input_ids_batch, attention_mask_batch, labels_batch) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch + 1}\")):\n","            # Move batch data to the specified device\n","            input_ids_batch = input_ids_batch.to(device)\n","            attention_mask_batch = attention_mask_batch.to(device)\n","            labels_batch = labels_batch.to(device)\n","\n","            # Forward pass: compute model output and loss\n","            outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch, labels=labels_batch)\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            # Backward pass: compute gradients and update weights\n","            loss.backward()\n","            optimizer.step()\n","            lr_scheduler.step()\n","            optimizer.zero_grad()  # Reset gradients for the next iteration\n","\n","            # Optional: Log batch loss for detailed tracking\n","            if (batch_idx + 1) % 100 == 0: # Log every 100 batches\n","                logger.debug(f\"Epoch {epoch + 1}, Batch {batch_idx + 1} - Training Loss: {loss.item():.4f}\")\n","\n","        avg_loss = total_loss / len(train_loader)\n","        logger.info(f\"Epoch {epoch + 1} - Average Training Loss: {avg_loss:.4f}\")\n","\n","        # --- Validation Phase ---\n","        model.eval()  # Set model to evaluation mode\n","        all_logits = []\n","        all_labels = []\n","        with torch.no_grad():  # Disable gradient calculations during validation\n","            for input_ids_batch, attention_mask_batch, labels_batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch + 1}\"):\n","                # Move batch data to the specified device\n","                input_ids_batch = input_ids_batch.to(device)\n","                attention_mask_batch = attention_mask_batch.to(device)\n","                labels_batch = labels_batch.to(device)\n","\n","                # Forward pass: compute model output (no labels for loss in validation pass)\n","                outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch)\n","                all_logits.append(outputs.logits)\n","                all_labels.append(labels_batch)\n","\n","        # Concatenate all collected logits and labels from validation batches\n","        logits = torch.cat(all_logits)\n","        labels_all = torch.cat(all_labels)\n","        # Compute metrics for the validation set\n","        val_acc, val_f1 = compute_metrics(logits, labels_all)\n","\n","        logger.info(f\"Epoch {epoch + 1} | Validation Accuracy: {val_acc:.4f} | Validation F1-Score: {val_f1:.4f}\")\n","\n","    logger.info(\"Training and validation complete.\")\n"]},{"cell_type":"markdown","source":["## 8. Main Execution Block\n","\n","This block orchestrates the entire fine-tuning process by calling the functions defined above. It also includes error handling for the main execution flow and an optional section to save the fine-tuned model."],"metadata":{"id":"main_execution_markdown"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"main_execution_code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["becc4537f73348209063fe2b1df598b0","61524bbc2acb468087013b08ccde0b6a","d7b6501c6d48459aa2863af75cff87d3","ca7f88428f3c41168ae61da2c5795442","edd93b820b4b4a6ca095309962c0a785","9e69ceb26e144a8089226e14a1c41104","a604e3e1a66949338f740fbb54b41737","dc92fa36e3cf4fa09818aad62b2ad4ef","dd05448c6a764361b563e16c21ad7a54","bd9a12ee54b843f78a594e7a91118140","bbe5986cea7346948841454ba3131a27","64654926d29c4a94bf5c4c53d713d227","b8e0d2be3b5745579468a1d19ad066b3","97854ec8707f4100a7be89b5d6e83667","f7e43869170e4409b5603c8d74b195c8","9dc61cff535a42ee982f081acbfdd36b","dc3c3849ec3b41769e8741dcf65a1c0a","622baab8572145ff8ee498b4813d03d6","c181af71d85f4f1db0e6ae792d333ead","e6ff29cad73942ceace15846d9923c00","ca386374048c42cbacd15b0f8a40d6d1","9a6024847bd34c7faa917a00f14711a1","ec50e6fdba6640a9b1a698bd26946d6e","0613c7ba398447659234348b783445a9","67bf3fa2d00a40059f5ecadb548a2c9a","de57dece0ff94526a5722cbeb50c8af1","7fdfa112ca004b0f955195f4c76f1907","8179710239894ed4ac0f4ff6cfd00753","98bbc134f9f84aeb811f744786a8ada9","eda58a4be3de4bc680f76fe88f47db15","7698d5caefc1445f871ebf30a38cf8e4","2f2aed6b56264b54bfb8f224e27279d8","8f8b37de4ab94d8c818c498ba2b0bf3c"]},"executionInfo":{"status":"ok","timestamp":1752095459919,"user_tz":-360,"elapsed":93519,"user":{"displayName":"hulu world","userId":"05131870956520847838"}},"outputId":"dee245f4-1c65-411b-dd67-3aaccc02b33e"},"outputs":[{"output_type":"stream","name":"stderr","text":["2025-07-09 21:09:25,535 - __main__ - INFO - Starting fine-tuning script. Current device: cuda\n","2025-07-09 21:09:25,535 - __main__ - INFO - Starting fine-tuning script. Current device: cuda\n","2025-07-09 21:09:25,535 - __main__ - INFO - Starting fine-tuning script. Current device: cuda\n","INFO:__main__:Starting fine-tuning script. Current device: cuda\n","2025-07-09 21:09:25,539 - __main__ - INFO - Loading preprocessed tensors from: /content...\n","2025-07-09 21:09:25,539 - __main__ - INFO - Loading preprocessed tensors from: /content...\n","2025-07-09 21:09:25,539 - __main__ - INFO - Loading preprocessed tensors from: /content...\n","INFO:__main__:Loading preprocessed tensors from: /content...\n","2025-07-09 21:09:25,570 - __main__ - INFO - Unique labels loaded: tensor([0, 1, 2])\n","2025-07-09 21:09:25,570 - __main__ - INFO - Unique labels loaded: tensor([0, 1, 2])\n","2025-07-09 21:09:25,570 - __main__ - INFO - Unique labels loaded: tensor([0, 1, 2])\n","INFO:__main__:Unique labels loaded: tensor([0, 1, 2])\n","2025-07-09 21:09:25,576 - __main__ - INFO - Preprocessed tensors loaded and labels validated successfully.\n","2025-07-09 21:09:25,576 - __main__ - INFO - Preprocessed tensors loaded and labels validated successfully.\n","2025-07-09 21:09:25,576 - __main__ - INFO - Preprocessed tensors loaded and labels validated successfully.\n","INFO:__main__:Preprocessed tensors loaded and labels validated successfully.\n","2025-07-09 21:09:25,578 - __main__ - INFO - Creating DataLoaders...\n","2025-07-09 21:09:25,578 - __main__ - INFO - Creating DataLoaders...\n","2025-07-09 21:09:25,578 - __main__ - INFO - Creating DataLoaders...\n","INFO:__main__:Creating DataLoaders...\n","2025-07-09 21:09:25,583 - __main__ - INFO - Train dataset size: 1811, Validation dataset size: 453\n","2025-07-09 21:09:25,583 - __main__ - INFO - Train dataset size: 1811, Validation dataset size: 453\n","2025-07-09 21:09:25,583 - __main__ - INFO - Train dataset size: 1811, Validation dataset size: 453\n","INFO:__main__:Train dataset size: 1811, Validation dataset size: 453\n","2025-07-09 21:09:25,586 - __main__ - INFO - DataLoaders created successfully.\n","2025-07-09 21:09:25,586 - __main__ - INFO - DataLoaders created successfully.\n","2025-07-09 21:09:25,586 - __main__ - INFO - DataLoaders created successfully.\n","INFO:__main__:DataLoaders created successfully.\n","2025-07-09 21:09:25,588 - __main__ - INFO - Loading model, optimizer, and scheduler...\n","2025-07-09 21:09:25,588 - __main__ - INFO - Loading model, optimizer, and scheduler...\n","2025-07-09 21:09:25,588 - __main__ - INFO - Loading model, optimizer, and scheduler...\n","INFO:__main__:Loading model, optimizer, and scheduler...\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becc4537f73348209063fe2b1df598b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64654926d29c4a94bf5c4c53d713d227"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec50e6fdba6640a9b1a698bd26946d6e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2025-07-09 21:09:39,361 - __main__ - INFO - Model, optimizer, and scheduler initialized successfully.\n","2025-07-09 21:09:39,361 - __main__ - INFO - Model, optimizer, and scheduler initialized successfully.\n","2025-07-09 21:09:39,361 - __main__ - INFO - Model, optimizer, and scheduler initialized successfully.\n","INFO:__main__:Model, optimizer, and scheduler initialized successfully.\n","2025-07-09 21:09:39,364 - __main__ - INFO - Starting training and validation loop...\n","2025-07-09 21:09:39,364 - __main__ - INFO - Starting training and validation loop...\n","2025-07-09 21:09:39,364 - __main__ - INFO - Starting training and validation loop...\n","INFO:__main__:Starting training and validation loop...\n","\n","Training Epoch 1:   0%|          | 0/114 [00:00<?, ?it/s]\u001b[A\n","Training Epoch 1:   1%|          | 1/114 [00:01<02:57,  1.57s/it]\u001b[A\n","Training Epoch 1:   2%|▏         | 2/114 [00:02<01:44,  1.07it/s]\u001b[A\n","Training Epoch 1:   3%|▎         | 3/114 [00:02<01:15,  1.47it/s]\u001b[A\n","Training Epoch 1:   4%|▎         | 4/114 [00:02<01:01,  1.78it/s]\u001b[A\n","Training Epoch 1:   4%|▍         | 5/114 [00:03<00:52,  2.06it/s]\u001b[A\n","Training Epoch 1:   5%|▌         | 6/114 [00:03<00:43,  2.46it/s]\u001b[A\n","Training Epoch 1:   6%|▌         | 7/114 [00:03<00:43,  2.45it/s]\u001b[A\n","Training Epoch 1:   7%|▋         | 8/114 [00:04<00:43,  2.45it/s]\u001b[A\n","Training Epoch 1:   8%|▊         | 9/114 [00:04<00:38,  2.73it/s]\u001b[A\n","Training Epoch 1:   9%|▉         | 10/114 [00:04<00:32,  3.16it/s]\u001b[A\n","Training Epoch 1:  10%|▉         | 11/114 [00:04<00:29,  3.51it/s]\u001b[A\n","Training Epoch 1:  11%|█         | 12/114 [00:05<00:26,  3.86it/s]\u001b[A\n","Training Epoch 1:  11%|█▏        | 13/114 [00:05<00:24,  4.11it/s]\u001b[A\n","Training Epoch 1:  12%|█▏        | 14/114 [00:05<00:23,  4.35it/s]\u001b[A\n","Training Epoch 1:  13%|█▎        | 15/114 [00:05<00:22,  4.48it/s]\u001b[A\n","Training Epoch 1:  14%|█▍        | 16/114 [00:05<00:21,  4.64it/s]\u001b[A\n","Training Epoch 1:  15%|█▍        | 17/114 [00:06<00:20,  4.76it/s]\u001b[A\n","Training Epoch 1:  16%|█▌        | 18/114 [00:06<00:20,  4.66it/s]\u001b[A\n","Training Epoch 1:  17%|█▋        | 19/114 [00:06<00:20,  4.61it/s]\u001b[A\n","Training Epoch 1:  18%|█▊        | 20/114 [00:06<00:19,  4.71it/s]\u001b[A\n","Training Epoch 1:  18%|█▊        | 21/114 [00:06<00:19,  4.78it/s]\u001b[A\n","Training Epoch 1:  19%|█▉        | 22/114 [00:07<00:18,  4.87it/s]\u001b[A\n","Training Epoch 1:  20%|██        | 23/114 [00:07<00:18,  4.91it/s]\u001b[A\n","Training Epoch 1:  21%|██        | 24/114 [00:07<00:18,  4.98it/s]\u001b[A\n","Training Epoch 1:  22%|██▏       | 25/114 [00:07<00:17,  4.99it/s]\u001b[A\n","Training Epoch 1:  23%|██▎       | 26/114 [00:07<00:17,  5.04it/s]\u001b[A\n","Training Epoch 1:  24%|██▎       | 27/114 [00:08<00:17,  5.06it/s]\u001b[A\n","Training Epoch 1:  25%|██▍       | 28/114 [00:08<00:17,  5.03it/s]\u001b[A\n","Training Epoch 1:  25%|██▌       | 29/114 [00:08<00:16,  5.07it/s]\u001b[A\n","Training Epoch 1:  26%|██▋       | 30/114 [00:08<00:16,  5.09it/s]\u001b[A\n","Training Epoch 1:  27%|██▋       | 31/114 [00:08<00:16,  5.08it/s]\u001b[A\n","Training Epoch 1:  28%|██▊       | 32/114 [00:09<00:16,  5.10it/s]\u001b[A\n","Training Epoch 1:  29%|██▉       | 33/114 [00:09<00:15,  5.11it/s]\u001b[A\n","Training Epoch 1:  30%|██▉       | 34/114 [00:09<00:15,  5.11it/s]\u001b[A\n","Training Epoch 1:  31%|███       | 35/114 [00:09<00:15,  5.09it/s]\u001b[A\n","Training Epoch 1:  32%|███▏      | 36/114 [00:09<00:16,  4.83it/s]\u001b[A\n","Training Epoch 1:  32%|███▏      | 37/114 [00:10<00:15,  4.82it/s]\u001b[A\n","Training Epoch 1:  33%|███▎      | 38/114 [00:10<00:15,  4.76it/s]\u001b[A\n","Training Epoch 1:  34%|███▍      | 39/114 [00:10<00:15,  4.73it/s]\u001b[A\n","Training Epoch 1:  35%|███▌      | 40/114 [00:10<00:15,  4.78it/s]\u001b[A\n","Training Epoch 1:  36%|███▌      | 41/114 [00:11<00:15,  4.75it/s]\u001b[A\n","Training Epoch 1:  37%|███▋      | 42/114 [00:11<00:15,  4.69it/s]\u001b[A\n","Training Epoch 1:  38%|███▊      | 43/114 [00:11<00:15,  4.61it/s]\u001b[A\n","Training Epoch 1:  39%|███▊      | 44/114 [00:11<00:15,  4.62it/s]\u001b[A\n","Training Epoch 1:  39%|███▉      | 45/114 [00:11<00:15,  4.59it/s]\u001b[A\n","Training Epoch 1:  40%|████      | 46/114 [00:12<00:14,  4.69it/s]\u001b[A\n","Training Epoch 1:  41%|████      | 47/114 [00:12<00:13,  4.80it/s]\u001b[A\n","Training Epoch 1:  42%|████▏     | 48/114 [00:12<00:13,  4.84it/s]\u001b[A\n","Training Epoch 1:  43%|████▎     | 49/114 [00:12<00:13,  4.89it/s]\u001b[A\n","Training Epoch 1:  44%|████▍     | 50/114 [00:12<00:12,  4.93it/s]\u001b[A\n","Training Epoch 1:  45%|████▍     | 51/114 [00:13<00:12,  4.90it/s]\u001b[A\n","Training Epoch 1:  46%|████▌     | 52/114 [00:13<00:12,  4.96it/s]\u001b[A\n","Training Epoch 1:  46%|████▋     | 53/114 [00:13<00:12,  5.00it/s]\u001b[A\n","Training Epoch 1:  47%|████▋     | 54/114 [00:13<00:11,  5.02it/s]\u001b[A\n","Training Epoch 1:  48%|████▊     | 55/114 [00:13<00:11,  5.03it/s]\u001b[A\n","Training Epoch 1:  49%|████▉     | 56/114 [00:14<00:11,  5.03it/s]\u001b[A\n","Training Epoch 1:  50%|█████     | 57/114 [00:14<00:11,  5.02it/s]\u001b[A\n","Training Epoch 1:  51%|█████     | 58/114 [00:14<00:11,  4.94it/s]\u001b[A\n","Training Epoch 1:  52%|█████▏    | 59/114 [00:14<00:10,  5.00it/s]\u001b[A\n","Training Epoch 1:  53%|█████▎    | 60/114 [00:14<00:10,  5.03it/s]\u001b[A\n","Training Epoch 1:  54%|█████▎    | 61/114 [00:15<00:10,  5.03it/s]\u001b[A\n","Training Epoch 1:  54%|█████▍    | 62/114 [00:15<00:10,  5.02it/s]\u001b[A\n","Training Epoch 1:  55%|█████▌    | 63/114 [00:15<00:10,  5.00it/s]\u001b[A\n","Training Epoch 1:  56%|█████▌    | 64/114 [00:15<00:09,  5.01it/s]\u001b[A\n","Training Epoch 1:  57%|█████▋    | 65/114 [00:15<00:09,  4.98it/s]\u001b[A\n","Training Epoch 1:  58%|█████▊    | 66/114 [00:16<00:09,  4.95it/s]\u001b[A\n","Training Epoch 1:  59%|█████▉    | 67/114 [00:16<00:09,  4.98it/s]\u001b[A\n","Training Epoch 1:  60%|█████▉    | 68/114 [00:16<00:09,  4.97it/s]\u001b[A\n","Training Epoch 1:  61%|██████    | 69/114 [00:16<00:08,  5.00it/s]\u001b[A\n","Training Epoch 1:  61%|██████▏   | 70/114 [00:16<00:08,  4.99it/s]\u001b[A\n","Training Epoch 1:  62%|██████▏   | 71/114 [00:17<00:08,  4.94it/s]\u001b[A\n","Training Epoch 1:  63%|██████▎   | 72/114 [00:17<00:08,  4.98it/s]\u001b[A\n","Training Epoch 1:  64%|██████▍   | 73/114 [00:17<00:08,  4.92it/s]\u001b[A\n","Training Epoch 1:  65%|██████▍   | 74/114 [00:17<00:08,  4.96it/s]\u001b[A\n","Training Epoch 1:  66%|██████▌   | 75/114 [00:17<00:07,  4.99it/s]\u001b[A\n","Training Epoch 1:  67%|██████▋   | 76/114 [00:18<00:07,  5.02it/s]\u001b[A\n","Training Epoch 1:  68%|██████▊   | 77/114 [00:18<00:07,  5.03it/s]\u001b[A\n","Training Epoch 1:  68%|██████▊   | 78/114 [00:18<00:07,  5.01it/s]\u001b[A\n","Training Epoch 1:  69%|██████▉   | 79/114 [00:18<00:06,  5.01it/s]\u001b[A\n","Training Epoch 1:  70%|███████   | 80/114 [00:18<00:06,  4.96it/s]\u001b[A\n","Training Epoch 1:  71%|███████   | 81/114 [00:19<00:06,  4.94it/s]\u001b[A\n","Training Epoch 1:  72%|███████▏  | 82/114 [00:19<00:06,  4.94it/s]\u001b[A\n","Training Epoch 1:  73%|███████▎  | 83/114 [00:19<00:06,  4.94it/s]\u001b[A\n","Training Epoch 1:  74%|███████▎  | 84/114 [00:19<00:06,  4.97it/s]\u001b[A\n","Training Epoch 1:  75%|███████▍  | 85/114 [00:19<00:05,  4.99it/s]\u001b[A\n","Training Epoch 1:  75%|███████▌  | 86/114 [00:20<00:05,  5.03it/s]\u001b[A\n","Training Epoch 1:  76%|███████▋  | 87/114 [00:20<00:05,  5.04it/s]\u001b[A\n","Training Epoch 1:  77%|███████▋  | 88/114 [00:20<00:05,  5.02it/s]\u001b[A\n","Training Epoch 1:  78%|███████▊  | 89/114 [00:20<00:04,  5.02it/s]\u001b[A\n","Training Epoch 1:  79%|███████▉  | 90/114 [00:20<00:04,  5.01it/s]\u001b[A\n","Training Epoch 1:  80%|███████▉  | 91/114 [00:21<00:04,  5.01it/s]\u001b[A\n","Training Epoch 1:  81%|████████  | 92/114 [00:21<00:04,  5.02it/s]\u001b[A\n","Training Epoch 1:  82%|████████▏ | 93/114 [00:21<00:04,  5.02it/s]\u001b[A\n","Training Epoch 1:  82%|████████▏ | 94/114 [00:21<00:03,  5.03it/s]\u001b[A\n","Training Epoch 1:  83%|████████▎ | 95/114 [00:21<00:03,  5.00it/s]\u001b[A\n","Training Epoch 1:  84%|████████▍ | 96/114 [00:22<00:03,  4.79it/s]\u001b[A\n","Training Epoch 1:  85%|████████▌ | 97/114 [00:22<00:03,  4.69it/s]\u001b[A\n","Training Epoch 1:  86%|████████▌ | 98/114 [00:22<00:03,  4.68it/s]\u001b[A\n","Training Epoch 1:  87%|████████▋ | 99/114 [00:22<00:03,  4.71it/s]\u001b[A\n","Training Epoch 1:  88%|████████▊ | 100/114 [00:23<00:02,  4.72it/s]\u001b[A\n","Training Epoch 1:  89%|████████▊ | 101/114 [00:23<00:02,  4.74it/s]\u001b[A\n","Training Epoch 1:  89%|████████▉ | 102/114 [00:23<00:02,  4.54it/s]\u001b[A\n","Training Epoch 1:  90%|█████████ | 103/114 [00:23<00:02,  4.55it/s]\u001b[A\n","Training Epoch 1:  91%|█████████ | 104/114 [00:23<00:02,  4.56it/s]\u001b[A\n","Training Epoch 1:  92%|█████████▏| 105/114 [00:24<00:01,  4.56it/s]\u001b[A\n","Training Epoch 1:  93%|█████████▎| 106/114 [00:24<00:01,  4.68it/s]\u001b[A\n","Training Epoch 1:  94%|█████████▍| 107/114 [00:24<00:01,  4.69it/s]\u001b[A\n","Training Epoch 1:  95%|█████████▍| 108/114 [00:24<00:01,  4.78it/s]\u001b[A\n","Training Epoch 1:  96%|█████████▌| 109/114 [00:24<00:01,  4.84it/s]\u001b[A\n","Training Epoch 1:  96%|█████████▋| 110/114 [00:25<00:00,  4.90it/s]\u001b[A\n","Training Epoch 1:  97%|█████████▋| 111/114 [00:25<00:00,  4.92it/s]\u001b[A\n","Training Epoch 1:  98%|█████████▊| 112/114 [00:25<00:00,  4.83it/s]\u001b[A\n","Training Epoch 1:  99%|█████████▉| 113/114 [00:25<00:00,  4.88it/s]\u001b[A\n","Training Epoch 1: 100%|██████████| 114/114 [00:25<00:00,  4.41it/s]\n","2025-07-09 21:10:05,223 - __main__ - INFO - Epoch 1 - Average Training Loss: 0.6072\n","2025-07-09 21:10:05,223 - __main__ - INFO - Epoch 1 - Average Training Loss: 0.6072\n","2025-07-09 21:10:05,223 - __main__ - INFO - Epoch 1 - Average Training Loss: 0.6072\n","INFO:__main__:Epoch 1 - Average Training Loss: 0.6072\n","Validation Epoch 1: 100%|██████████| 29/29 [00:01<00:00, 18.23it/s]\n","2025-07-09 21:10:06,868 - __main__ - INFO - Epoch 1 | Validation Accuracy: 0.9382 | Validation F1-Score: 0.9376\n","2025-07-09 21:10:06,868 - __main__ - INFO - Epoch 1 | Validation Accuracy: 0.9382 | Validation F1-Score: 0.9376\n","2025-07-09 21:10:06,868 - __main__ - INFO - Epoch 1 | Validation Accuracy: 0.9382 | Validation F1-Score: 0.9376\n","INFO:__main__:Epoch 1 | Validation Accuracy: 0.9382 | Validation F1-Score: 0.9376\n","Training Epoch 2: 100%|██████████| 114/114 [00:23<00:00,  4.85it/s]\n","2025-07-09 21:10:30,381 - __main__ - INFO - Epoch 2 - Average Training Loss: 0.1427\n","2025-07-09 21:10:30,381 - __main__ - INFO - Epoch 2 - Average Training Loss: 0.1427\n","2025-07-09 21:10:30,381 - __main__ - INFO - Epoch 2 - Average Training Loss: 0.1427\n","INFO:__main__:Epoch 2 - Average Training Loss: 0.1427\n","Validation Epoch 2: 100%|██████████| 29/29 [00:01<00:00, 17.56it/s]\n","2025-07-09 21:10:32,045 - __main__ - INFO - Epoch 2 | Validation Accuracy: 0.9735 | Validation F1-Score: 0.9735\n","2025-07-09 21:10:32,045 - __main__ - INFO - Epoch 2 | Validation Accuracy: 0.9735 | Validation F1-Score: 0.9735\n","2025-07-09 21:10:32,045 - __main__ - INFO - Epoch 2 | Validation Accuracy: 0.9735 | Validation F1-Score: 0.9735\n","INFO:__main__:Epoch 2 | Validation Accuracy: 0.9735 | Validation F1-Score: 0.9735\n","Training Epoch 3: 100%|██████████| 114/114 [00:23<00:00,  4.75it/s]\n","2025-07-09 21:10:56,034 - __main__ - INFO - Epoch 3 - Average Training Loss: 0.0648\n","2025-07-09 21:10:56,034 - __main__ - INFO - Epoch 3 - Average Training Loss: 0.0648\n","2025-07-09 21:10:56,034 - __main__ - INFO - Epoch 3 - Average Training Loss: 0.0648\n","INFO:__main__:Epoch 3 - Average Training Loss: 0.0648\n","Validation Epoch 3: 100%|██████████| 29/29 [00:01<00:00, 16.88it/s]\n","2025-07-09 21:10:57,763 - __main__ - INFO - Epoch 3 | Validation Accuracy: 0.9691 | Validation F1-Score: 0.9691\n","2025-07-09 21:10:57,763 - __main__ - INFO - Epoch 3 | Validation Accuracy: 0.9691 | Validation F1-Score: 0.9691\n","2025-07-09 21:10:57,763 - __main__ - INFO - Epoch 3 | Validation Accuracy: 0.9691 | Validation F1-Score: 0.9691\n","INFO:__main__:Epoch 3 | Validation Accuracy: 0.9691 | Validation F1-Score: 0.9691\n","2025-07-09 21:10:57,767 - __main__ - INFO - Training and validation complete.\n","2025-07-09 21:10:57,767 - __main__ - INFO - Training and validation complete.\n","2025-07-09 21:10:57,767 - __main__ - INFO - Training and validation complete.\n","INFO:__main__:Training and validation complete.\n","2025-07-09 21:10:59,167 - __main__ - INFO - Fine-tuned model saved to ./finetuned_finbert\n","2025-07-09 21:10:59,167 - __main__ - INFO - Fine-tuned model saved to ./finetuned_finbert\n","2025-07-09 21:10:59,167 - __main__ - INFO - Fine-tuned model saved to ./finetuned_finbert\n","INFO:__main__:Fine-tuned model saved to ./finetuned_finbert\n"]}],"source":["# --- Main Execution Block ---\n","if __name__ == \"__main__\":\n","    logger.info(f\"Starting fine-tuning script. Current device: {DEVICE}\")\n","\n","    try:\n","        # 1. Load Data\n","        input_ids, attention_mask, labels = load_preprocessed_tensors(DATA_DIR, NUM_LABELS)\n","\n","        # 2. Create DataLoaders\n","        train_loader, val_loader = create_dataloaders(input_ids, attention_mask, labels, BATCH_SIZE)\n","\n","        # 3. Setup Model, Optimizer, and Scheduler\n","        model, optimizer, lr_scheduler = setup_model_optimizer_scheduler(\n","            MODEL_NAME, NUM_LABELS, LEARNING_RATE, train_loader, EPOCHS, DEVICE\n","        )\n","\n","        # 4. Train and Validate Model\n","        train_and_validate(model, train_loader, val_loader, optimizer, lr_scheduler, EPOCHS, DEVICE)\n","\n","        # Save the fine-tuned model\n","        model_save_path = \"./finetuned_finbert\"\n","        model.save_pretrained(model_save_path)\n","        logger.info(f\"Fine-tuned model saved to {model_save_path}\")\n","\n","    except Exception as e:\n","        logger.critical(f\"An unhandled error occurred during the fine-tuning process: {e}\", exc_info=True)\n"]}]}